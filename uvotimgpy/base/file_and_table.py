import os
from astropy.io import fits
from datetime import datetime
from astropy.time import Time, TimeDelta
import numpy as np
from typing import Union, Tuple, List, Dict, Any, Optional
from astropy.table import Table
import subprocess
from pathlib import Path
import inspect
import ipynbname
import pandas as pd
import astropy.units as u
from astropy.units import Quantity
from uvotimgpy.config import paths
from sbpy.data import Ephem
import csv
import re
from astropy.coordinates import SkyCoord
import matplotlib.dates as mdates



def save_astropy_table(data_table, output_path, verbose=True):
    """
    Save an Astropy table to a file.

    Parameters:
    data_table (astropy.table.Table): The Astropy table to save.
    output_path (str): Absolute path for the output file. ecsv recommended.
    """
    #os.makedirs(os.path.dirname(output_path), exist_ok=True)
    if isinstance(data_table, Table):
        data_table.write(output_path, overwrite=True, delimiter=',')
        if verbose:
            file_format = str(output_path).split('.')[-1]
            print(f"Data saved to: {output_path}, format: {file_format}")

def show_or_save_astropy_table(data_table, output_path=None):
    """
    Process an Astropy table by either saving it to a file or printing it to console.

    Parameters:
    data_table (astropy.table.Table): The Astropy table to process.
    output_path (str, optional): Path for the output file. If None, the table will be printed to console. For saving, absolute is recommended.
    """
    if output_path is None:
        data_table.pprint(max_lines=-1, max_width=-1)
    else:
        save_astropy_table(data_table, output_path)

def load_table(table_path, type='astropy_table', verbose=True):
    if verbose:
        file_format = str(table_path).split('.')[-1]
        print(f"Loading data from: {table_path}, format: {file_format}")
    file_path = Path(table_path)
    if not file_path.exists():
        raise FileNotFoundError(f"File not found: {file_path}")
    
    if type == 'df' and file_path.suffix.lower() == '.csv':
        # CSVæ–‡ä»¶
        dtype_dict = {'OBSID': str} if 'OBSID' in pd.read_csv(file_path, nrows=0).columns else {}
        df = pd.read_csv(file_path, dtype=dtype_dict)
        return df
    elif type == 'astropy_table' and file_path.suffix.lower() in ['.ecsv', '.csv']:
        # ECSVæ–‡ä»¶ (astropyæ ¼å¼)
        table = Table.read(file_path)
        return table 
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_path.suffix}")

def is_dict_list(obj) -> bool:
    return (
        isinstance(obj, list)
        and all(isinstance(item, dict) for item in obj)
    )

def is_list_dict(obj) -> bool:
    return (
        isinstance(obj, dict)
        and all(isinstance(v, list) for v in obj.values())
        and len(set(len(v) for v in obj.values())) <= 1  # å¯é€‰ï¼šæ‰€æœ‰åˆ—è¡¨é•¿åº¦ä¸€è‡´
    )

def remove_table_units(table):
    """
    é€šè¿‡è½¬æ¢ä¸º pandas DataFrame æ¥ç§»é™¤astropy Tableçš„å•ä½
    """
    # è½¬æ¢ä¸º pandas DataFrameï¼ˆè‡ªåŠ¨ç§»é™¤å•ä½ï¼‰
    df = table.to_pandas()
    
    # è½¬å› astropy Table
    return Table.from_pandas(df)

class TableConverter:
    @staticmethod
    def df_to_astropy_table(df: pd.DataFrame) -> Table:
        """
        Convert a DataFrame to an Astropy Table.
        Assumes each value in the DataFrame is either:
        - a Quantity (e.g., [1*u.km, 2*u.km]) [RECOMMENDED]
        - or a normal scalar
        """
        table = Table()
        for col in df.columns:
            col_data = df[col]
            if isinstance(col_data.iloc[0], Quantity):
                table[col] = u.Quantity(col_data.tolist())
            else:
                table[col] = col_data.tolist()
        return table

    @staticmethod
    def astropy_table_to_df(table: Table) -> pd.DataFrame:
        """Convert Astropy Table to DataFrame. Each value will be Quantity if the column has units."""
        data = {}
        for col in table.colnames:
            col_data = table[col]
            if hasattr(col_data, 'unit') and col_data.unit is not None:
                data[col] = [val * col_data.unit for val in col_data]
            else:
                data[col] = col_data.tolist()
        return pd.DataFrame(data)

    @staticmethod
    def astropy_table_to_dict_list(table: Table) -> List[Dict[str, Any]]:
        """Convert Astropy Table to list of dicts. Values preserve units as Quantities."""
        rows = []
        for row in table:
            row_dict = {}
            for col in table.colnames:
                val = row[col]
                if hasattr(table[col], 'unit') and table[col].unit is not None:
                    row_dict[col] = val * table[col].unit
                else:
                    row_dict[col] = val
            rows.append(row_dict)
        return rows

    @staticmethod
    def dict_list_to_astropy_table(dict_list: List[Dict[str, Any]]) -> Table:
        """Convert list of dicts to Astropy Table. Quantities are recognized and units applied."""
        if not dict_list:
            return Table()
        columns = {}
        for key in dict_list[0].keys():
            col_values = [d[key] for d in dict_list]
            if isinstance(col_values[0], Quantity):
                columns[key] = u.Quantity(col_values)
            else:
                columns[key] = col_values
        return Table(columns)

    @staticmethod
    def astropy_table_to_list_dict(table: Table) -> Dict[str, List[Any]]:
        """Convert Astropy Table to dict of lists. Preserves units using Quantities."""
        result = {}
        for col in table.colnames:
            col_data = table[col]
            if hasattr(col_data, 'unit') and col_data.unit is not None:
                result[col] = [val * col_data.unit for val in col_data]
            else:
                result[col] = col_data.tolist()
        return result

    @staticmethod
    def list_dict_to_astropy_table(list_dict: Dict[str, List[Any]]) -> Table:
        """Convert dict of lists to Astropy Table. Quantities are recognized and units applied."""
        if not list_dict:
            return Table()
        lengths = {len(v) for v in list_dict.values()}
        if len(lengths) != 1:
            raise ValueError("All lists must have the same length.")
        columns = {}
        for key, values in list_dict.items():
            if isinstance(values[0], Quantity):
                columns[key] = u.Quantity(values)
            else:
                columns[key] = values
        return Table(columns)
    
    @staticmethod
    def df_to_dict_list(df: pd.DataFrame) -> List[Dict[str, Any]]:
        """Convert a DataFrame to a list of dictionaries."""
        if df.empty:
            return []
        return df.to_dict(orient='records')
    
    @staticmethod
    def dict_list_to_df(dict_list: List[Dict[str, Any]]) -> pd.DataFrame:
        """Convert a list of dictionaries to a DataFrame."""
        if not dict_list:
            return pd.DataFrame()
        return pd.DataFrame(dict_list)
    
    @staticmethod
    def dict_list_to_list_dict(dict_list: List[Dict[str, Any]]) -> Dict[str, List[Any]]:
        if not dict_list:
            return {}
        keys = dict_list[0].keys()
        return {key: [d[key] for d in dict_list] for key in keys}

    @staticmethod
    def list_dict_to_dict_list(list_dict: Dict[str, List[Any]]) -> List[Dict[str, Any]]:
        if not list_dict:
            return []
        lengths = {len(v) for v in list_dict.values()}
        if len(lengths) != 1:
            raise ValueError("All lists in the dictionary must have the same length.")
        keys = list_dict.keys()
        length = next(iter(lengths))
        return [{key: list_dict[key][i] for key in keys} for i in range(length)]
    

def expand_quantity_in_dict(data: Dict[str, List[Any]]) -> Dict[str, List[Any]]:
    """
    éå† dict ä¸­æ‰€æœ‰åˆ—ï¼ˆlistï¼‰ï¼Œè‹¥æŸåˆ—æ˜¯ Quantityï¼Œåˆ™å°†å…¶å±•å¼€ä¸ºå…ƒç´ ä¸º Quantity çš„åˆ—è¡¨ã€‚
    ä¾‹ï¼š[1, 2, 3]*u.km -> [1*u.km, 2*u.km, 3*u.km]
    Parameters:
        data: dict of listsï¼Œåˆ—åå¯¹åº”å€¼åˆ—è¡¨
    Returns:
        dict: æ–°çš„ dictï¼Œæ‰€æœ‰ Quantity ç±»å‹å·²è¢«å±•å¼€
    """
    result = {}
    for key, values in data.items():
        if isinstance(values, Quantity):
            result[key] = [v * values.unit for v in values.value]
        else:
            result[key] = values
    return result
    

def compress_quantity_in_dict(data: Dict[str, List[Any]]) -> Dict[str, List[Any]]:
    """
    å°† dict ä¸­æ‰€æœ‰åˆ—ï¼ˆlistï¼‰ä¸­å…ƒç´ å‡ä¸º Quantity çš„ï¼Œå‹ç¼©ä¸ºå•ä¸ª Quantity åˆ—ã€‚
    ä¾‹ï¼š[1*u.km, 2*u.km, 3*u.km] â†’ [1, 2, 3]*u.km
    Parameters:
        data: dict of listsï¼Œåˆ—åå¯¹åº”å€¼åˆ—è¡¨
    Returns:
        dict: æ–°çš„ dictï¼ŒQuantity åˆ—è¢«å‹ç¼©ä¸ºç»Ÿä¸€ Quantity
    """
    result = {}
    for key, values in data.items():
        if isinstance(values, list) and values and isinstance(values[0], Quantity):
            try:
                result[key] = u.Quantity(values)
            except Exception:
                # æœ‰å¯èƒ½å•ä½ä¸ä¸€è‡´ï¼Œå¦‚ [1*u.km, 2*u.m]ï¼Œåˆ™ä¸å‹ç¼©
                result[key] = values
        else:
            result[key] = values
    return result

class TableColumnManager:
    def __init__(self, table_like):
        self._original = table_like
        self.table = self._parse_table()

    def _parse_table(self):
        """è§£æ self._original æˆ astropy Table"""
        if isinstance(self._original, str) and os.path.isfile(self._original):
            return load_table(self._original)
        elif isinstance(self._original, pd.DataFrame):
            return TableConverter.df_to_astropy_table(self._original)
        elif isinstance(self._original, list) and is_dict_list(self._original):
            return TableConverter.dict_list_to_astropy_table(self._original)
        elif isinstance(self._original, dict) and is_list_dict(self._original):
            return TableConverter.list_dict_to_astropy_table(self._original)
        elif isinstance(self._original, Table):
            return self._original
        else:
            raise ValueError("Unsupported table format.")

    def _save(self):
        """å¦‚æœè¾“å…¥æ˜¯è·¯å¾„ï¼Œåˆ™ä¿å­˜åˆ°åŸè·¯å¾„"""
        ext = str(self._original).split('.')[-1].lower()
        if ext in ['csv', 'ecsv']:
            save_astropy_table(self.table, self._original, verbose=False)
            print(f"ğŸ’¾ Table saved to {self._original}")
        else:
            raise ValueError(f"Cannot determine format from extension: '{ext}'")

    def _get_table(self):
        if isinstance(self._original, pd.DataFrame):
            return TableConverter.astropy_table_to_df(self.table)
        elif isinstance(self._original, list) and is_dict_list(self._original):
            return TableConverter.astropy_table_to_dict_list(self.table)
        elif isinstance(self._original, dict) and is_list_dict(self._original):
            return TableConverter.astropy_table_to_list_dict(self.table)
        elif isinstance(self._original, Table):
            return self.table
        else:
            raise ValueError("Unsupported table format.")
        #return self.table

    @staticmethod
    def add_columns(table_like, new_columns: dict, after_column: str = None):
        manager = TableColumnManager(table_like)
        table = manager.table
        n_rows = len(table)

        wrong_length = [
            col for col, val in new_columns.items() if len(val) != n_rows
        ]
        if wrong_length:
            raise ValueError(f"âŒ Length mismatch: {wrong_length} (table has {n_rows} rows)")

        insert_at = len(table.columns)
        if after_column:
            if after_column not in table.colnames:
                raise ValueError(f"âŒ Column '{after_column}' not found.")
            insert_at = table.colnames.index(after_column) + 1

        for col_name, col_data in new_columns.items():
            table.add_column(col_data, name=col_name, index=insert_at)
            insert_at += 1

        print(f"âœ… Added columns: {list(new_columns.keys())}")
        return manager._save() if isinstance(table_like, str) else manager._get_table()

    @staticmethod
    def remove_columns(table_like, columns_to_remove):
        manager = TableColumnManager(table_like)
        table = manager.table

        if isinstance(columns_to_remove, str):
            columns_to_remove = [columns_to_remove]

        missing = [col for col in columns_to_remove if col not in table.colnames]
        if missing:
            raise ValueError(f"âŒ These columns do not exist: {missing}")

        table.remove_columns(columns_to_remove)
        print(f"âœ… Removed columns: {columns_to_remove}")
        return manager._save() if isinstance(table_like, str) else manager._get_table()
    
def get_caller_filename():
    """
    è·å–è°ƒç”¨è€…çš„æ–‡ä»¶åï¼Œæ”¯æŒæ™®é€šPythonè„šæœ¬å’ŒJupyter Notebook
    
    Returns
    -------
    str
        è°ƒç”¨è€…çš„æ–‡ä»¶å
        - å¯¹äºæ™®é€šPythonè„šæœ¬: è¿”å›è„šæœ¬æ–‡ä»¶å (å¦‚ 'script.py')
        - å¯¹äºJupyter Notebook: è¿”å›notebookæ–‡ä»¶å (å¦‚ 'analysis.ipynb')
        - å¦‚æœæ— æ³•è·å–: è¿”å›é»˜è®¤åç§°(Unknown)
    """
    
    frame = inspect.currentframe()
    try:
        # è·å–è°ƒç”¨è€…çš„frame (ä¸Šä¸€çº§è°ƒç”¨æ ˆ)
        caller_frame = frame.f_back
        caller_filename = caller_frame.f_code.co_filename
        
        # å¤„ç†jupyter notebookçš„æƒ…å†µ
        if caller_filename.startswith('<ipython-input-') or caller_filename == '<stdin>':
            try:
                # æ–¹æ³•1: å°è¯•ä»IPythonè·å–notebookåç§°
                notebook_path = ipynbname.path()
                return os.path.basename(notebook_path)
            except ImportError:
                try:
                    # æ–¹æ³•2: å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
                    if 'JPY_SESSION_NAME' in os.environ:
                        return os.environ['JPY_SESSION_NAME'] + '.ipynb'
                    else:
                        return "Unknown"
                except:
                    return "Unknown"
            except:
                return "Unknown"
        else:
            # æ™®é€šPythonè„šæœ¬
            return os.path.basename(caller_filename)
    finally:
        del frame

def compress_fits(fits_file, remove_original=True):
    fits_file = Path(fits_file)
    compressed_path = fits_file.with_name(fits_file.name + ".fz")
    if compressed_path.exists():
        os.remove(compressed_path)
    try:
        subprocess.run(["fpack", str(fits_file)], check=True)
        if remove_original:
            os.remove(fits_file)
    except subprocess.CalledProcessError as e:
        print("Compression failed:", e)

def ephemeris_keywords():
    # https://astroquery.readthedocs.io/en/latest/api/astroquery.jplhorizons.HorizonsClass.html#astroquery.jplhorizons.HorizonsClass.ephemerides
    return ['targetname', 'M1', 'solar_presence', 'k1', 'interfering_body', 'RA', 'DEC', 'RA_app', 'DEC_app',
            'RA*cos(Dec)_rate', 'DEC_rate', 'AZ', 'EL', 'AZ_rate', 'EL_rate', 'sat_X', 'sat_Y',
            'sat_PANG', 'siderealtime', 'airmass', 'magextinct', 'Tmag', 'Nmag', 'illumination', 'illum_defect',
            'sat_sep', 'sat_vis', 'ang_width', 'PDObsLon', 'PDObsLat', 'PDSunLon', 'PDSunLat',
            'SubSol_ang', 'SubSol_dist', 'NPole_ang', 'NPole_dist', 'EclLon', 'EclLat', 'r', 'r_rate',
            'delta', 'delta_rate', 'lighttime', 'vel_sun', 'vel_obs', 'elong', 'elongFlag',
            'alpha', 'IB_elong', 'IB_illum', 'sat_alpha', 'sunTargetPA', 'velocityPA', 'OrbPlaneAng',
            'constellation', 'TDB-UT', 'ObsEclLon', 'ObsEclLat', 'NPole_RA', 'NPole_DEC', 'GlxLon', 'GlxLat',
            'solartime', 'earth_lighttime', 'RA_3sigma', 'DEC_3sigma', 'SMAA_3sigma', 'SMIA_3sigma', 'Theta_3sigma',
            'Area_3sigma', 'RSS_3sigma', 'r_3sigma', 'r_rate_3sigma', 'SBand_3sigma', 'XBand_3sigma', 'DoppDelay_3sigma',
            'true_anom', 'hour_angle', 'alpha_true', 'PABLon', 'PABLat', 'epoch']

def create_time_array(start, end, step):
    """
    ä»å­—ç¬¦ä¸²å’Œ Quantity åˆ›å»ºæ—¶é—´æ•°ç»„
    
    å‚æ•°:
        start: str, å¼€å§‹æ—¶é—´å­—ç¬¦ä¸² (å¦‚ '2022-01-01' æˆ– '2022-01-01 00:00:00')
        end: str, ç»“æŸæ—¶é—´å­—ç¬¦ä¸²
        step: astropy Quantity, æ—¶é—´æ­¥é•¿ (å¦‚ 30*u.day, 2*u.hour)
    
    è¿”å›:
        astropy.time.Time æ•°ç»„
    """
    # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º Time å¯¹è±¡
    start_time = Time(start)
    end_time = Time(end)
    
    # å°† step è½¬æ¢ä¸º TimeDelta
    step_delta = TimeDelta(step)
    
    # ç”Ÿæˆæ—¶é—´æ•°ç»„
    times = []
    current = start_time
    while current <= end_time:
        times.append(current.isot)
        current = current + step_delta
    
    return Time(times)

def get_ephemeris_batch(times, target_id, location=500, orbital_keywords=None, batch_size=50):
    """
    åˆ†æ‰¹è·å–å†è¡¨æ•°æ®çš„è¾…åŠ©å‡½æ•°
    Parameters
    ----------
    times : array-like 'astropy.time.core.Time' object
        æ—¶é—´ç‚¹åˆ—è¡¨
    orbital_keywords : list
        éœ€è¦è·å–çš„è½¨é“å‚æ•°å…³é”®å­—åˆ—è¡¨
    batch_size : int
        æ¯æ‰¹å¤„ç†çš„æ—¶é—´ç‚¹æ•°é‡
    Returns
    -------
    Ephem 
        åˆå¹¶åçš„å†è¡¨æ•°æ®ï¼Œæ ¼å¼ä¸ç›´æ¥è°ƒç”¨eph[orbital_keywords]ç›¸åŒ
    """
    results = []  # å­˜å‚¨æ‰€æœ‰æ‰¹æ¬¡çš„ç»“æœ
    # åˆ†æ‰¹å¤„ç†
    for i in range(0, len(times), batch_size):
        try:
            batch_times = times[i:min(i + batch_size, len(times))]
            eph = Ephem.from_horizons(target_id, location=location, epochs=batch_times)
            results.append(eph)
        except Exception as e:
            if "Ambiguous target name" in str(e):
                print(f"è¯·æä¾›å‡†ç¡®çš„ç›®æ ‡IDã€‚é”™è¯¯: {str(e)}")
            else:
                print(f"é”™è¯¯: {str(e)}")
            raise
    # å¦‚æœåªæœ‰ä¸€æ‰¹æ•°æ®ï¼Œç›´æ¥è¿”å›
    if len(results) == 1:
        if orbital_keywords is None:
            return results[0]
        else:
            return results[0][orbital_keywords]
    # ä½¿ç”¨sbpyçš„vstackåˆå¹¶ç»“æœ
    final_eph = results[0]
    for eph in results[1:]:
        final_eph.vstack(eph)
    if orbital_keywords is None:
        return final_eph
    else:
        return final_eph[orbital_keywords]



def target_name_converter(input_value: str, output_type: str = 'all', csv_path: Optional[Union[str, Path]] = None) -> Optional[Union[str, Dict[str, str]]]:
    """
    å°†å½—æ˜Ÿçš„data_folder_nameã€target_simplified_nameæˆ–target_full_nameç›¸äº’è½¬æ¢
    
    å‚æ•°:
        input_value: è¾“å…¥çš„å½—æ˜Ÿåç§°ï¼ˆå¯ä»¥æ˜¯ä¸‰ç§æ ¼å¼ä¸­çš„ä»»æ„ä¸€ç§ï¼‰
        output_type: è¾“å‡ºç±»å‹
            - 'all': è¿”å›åŒ…å«æ‰€æœ‰ä¸‰ä¸ªå€¼çš„å­—å…¸ï¼ˆé»˜è®¤ï¼‰
            - 'data_folder_name': åªè¿”å›data_folder_name
            - 'target_simplified_name': åªè¿”å›target_simplified_name
            - 'target_full_name': åªè¿”å›target_full_name
        csv_file: CSVæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º'comets_data.csv'
    
    è¿”å›:
        æ ¹æ®output_typeè¿”å›ç›¸åº”çš„å€¼æˆ–å­—å…¸ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    
    ç¤ºä¾‹:
        >>> comet_name_converter('1P')
        {'data_folder_name': '1P', 'target_simplified_name': '1P/Halley', 'target_full_name': "1P/Halley (Halley's Comet)"}
        
        >>> comet_name_converter('C/2006 P1', 'data_folder_name')
        'C_2006P1'
        
        >>> comet_name_converter('2I/Borisov (Interstellar comet)', 'target_simplified_name')
        'C/2019 Q4'
    """
    if csv_path is None:
        csv_path = paths.get_subpath(paths.data, 'Swift', 'target_name.csv')
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"CSVæ–‡ä»¶ '{csv_path}' ä¸å­˜åœ¨")
    # è¯»å–CSVæ–‡ä»¶
    df = pd.read_csv(csv_path, sep=',')
    
    # åœ¨ä¸‰åˆ—ä¸­æŸ¥æ‰¾
    mask = (
        (df['data_folder_name'].str.lower() == input_value.lower()) |
        (df['target_simplified_name'].str.lower() == input_value.lower()) |
        (df['target_full_name'].str.lower() == input_value.lower())
    )
    
    result = df[mask]
    
    if result.empty:
        return None
    
    row = result.iloc[0]
    
    if output_type == 'all':
        return row.to_dict()
    elif output_type in ['data_folder_name', 'target_simplified_name', 'target_full_name']:
        return row[output_type]
    else:
        raise ValueError(f"æ— æ•ˆçš„output_type: {output_type}")

def _parse_orbital_line(line):
    """
    å°†è½¨é“å…ƒç´ å­—ç¬¦ä¸²è§£ææˆåˆ—è¡¨ï¼Œè‡ªåŠ¨è¯†åˆ«å¹¶æ‹†åˆ†RA/DECç»„åˆ
    
    æ—¥æœŸæ ¼å¼: 
    - 2026-Apr-01 00:00 (æ—¥æœŸ+æ—¶é—´ä½œä¸ºä¸€ä¸ªå…ƒç´ )
    - 2460035.500000000 (å„’ç•¥æ—¥)
    
    RA/DECæ¨¡å¼: 3ä¸ªæ•°å­— + 3ä¸ªæ•°å­—ï¼ˆå¯èƒ½å¸¦æ­£è´Ÿå·ï¼‰
    ä¾‹å¦‚: 16 45 53.94 -40 23 03.9
    """
    # ç§»é™¤ /L è¿™æ ·çš„æ ‡è®°
    line = re.sub(r'/[A-Za-z]+', '', line)
    
    # é¦–å…ˆå¤„ç†æ—¥æœŸæ—¶é—´ï¼ˆå¦‚æœæ˜¯ YYYY-Mon-DD HH:MM æˆ– HH:MM:SS æ ¼å¼ï¼Œåˆå¹¶ä¸ºä¸€ä¸ªå…ƒç´ ï¼‰
    date_time_pattern = r'(\d{4}-\w{3}-\d{1,2}\s+\d{1,2}:\d{2}(?::\d{2})?)'
    match = re.search(date_time_pattern, line)
    if match:
        datetime_str = match.group(1)
        line = line.replace(datetime_str, '__DATETIME__')
        parts = line.strip().split()
        parts = [datetime_str if p == '__DATETIME__' else p for p in parts]
    else:
        parts = line.strip().split()
    
    result = []
    i = 0
    
    while i < len(parts):
        # æ£€æŸ¥æ˜¯å¦å¯èƒ½æ˜¯RA/DECç»„åˆçš„å¼€å§‹ï¼ˆéœ€è¦è‡³å°‘6ä¸ªå…ƒç´ ï¼‰
        if i + 5 < len(parts):
            try:
                # æ£€æŸ¥æ˜¯å¦ç¬¦åˆRA/DECæ¨¡å¼
                h = float(parts[i])
                m = float(parts[i+1])
                s = float(parts[i+2])
                
                # DECçš„åº¦æ•°éƒ¨åˆ†ï¼ˆå¯èƒ½å¸¦ç¬¦å·ï¼‰
                dec_deg_str = parts[i+3]
                dec_m = float(parts[i+4])
                dec_s = float(parts[i+5])
                
                # æ›´ä¸¥æ ¼çš„RAæ£€æŸ¥ï¼š
                # 1. å°æ—¶åº”è¯¥æ˜¯æ•´æ•°æˆ–æ¥è¿‘æ•´æ•°ï¼ˆå¤©æ–‡åæ ‡é€šå¸¸å¦‚æ­¤ï¼‰
                # 2. å¯¹äºRAï¼Œç¬¬ä¸€ä¸ªæ•°å­—é€šå¸¸åœ¨0-23èŒƒå›´ä¸”ç»å¸¸æ˜¯æ•´æ•°
                # 3. DECçš„ç¬¬ä¸€ä¸ªæ•°å­—åº”è¯¥å¸¦ç¬¦å·æˆ–åœ¨-90åˆ°90èŒƒå›´å†…
                
                # æ£€æŸ¥ RA çš„å°æ—¶æ˜¯å¦åƒçœŸå®çš„å°æ—¶å€¼ï¼ˆé€šå¸¸æ˜¯æ•´æ•°æˆ–æœ€å¤š1ä½å°æ•°ï¼‰
                h_is_hour_like = (h == int(h)) or (h * 10 == int(h * 10))
                
                # æ£€æŸ¥ DEC åº¦æ•°æ˜¯å¦åƒçœŸå®çš„åº¦æ•°ï¼ˆå¸¦ç¬¦å·æˆ–åˆç†èŒƒå›´ï¼‰
                dec_deg_float = float(dec_deg_str)
                dec_is_deg_like = (
                    dec_deg_str.startswith('+') or 
                    dec_deg_str.startswith('-') or 
                    (-90 <= dec_deg_float <= 90 and '.' not in parts[i+3])  # åº¦æ•°é€šå¸¸æ˜¯æ•´æ•°
                )
                
                # é¢å¤–æ£€æŸ¥ï¼šåˆ†å’Œç§’çš„å°æ•°ä½æ•°ï¼ˆå¤©æ–‡åæ ‡é€šå¸¸ä¸ä¼šæœ‰å¤ªå¤šå°æ•°ä½ï¼‰
                m_decimal_places = len(str(m).split('.')[-1]) if '.' in str(m) else 0
                s_decimal_places = len(str(s).split('.')[-1]) if '.' in str(s) else 0
                
                # RA/DEC çš„åˆ†ç§’é€šå¸¸ä¸ä¼šæœ‰è¶…è¿‡2-3ä½å°æ•°
                reasonable_precision = (m_decimal_places <= 3 and s_decimal_places <= 3)
                
                if (0 <= h < 24 and 0 <= m < 60 and 0 <= s < 60 and
                    0 <= dec_m < 60 and 0 <= dec_s < 60 and
                    h_is_hour_like and dec_is_deg_like and reasonable_precision):
                    # è¿™æ˜¯ä¸€ä¸ªRA/DECç»„åˆ
                    ra = f"{parts[i]} {parts[i+1]} {parts[i+2]}"
                    dec = f"{parts[i+3]} {parts[i+4]} {parts[i+5]}"
                    result.append(ra)
                    result.append(dec)
                    i += 6
                    continue
            except (ValueError, IndexError):
                pass
        
        # ä¸æ˜¯RA/DECç»„åˆï¼Œç›´æ¥æ·»åŠ å½“å‰å…ƒç´ 
        result.append(parts[i])
        i += 1
    
    return result

def _format_orbital_dict(data_dict):
    """æ›´çµæ´»çš„ç‰ˆæœ¬ï¼Œä½¿ç”¨é…ç½®å®šä¹‰å¤„ç†æ–¹å¼"""
    
    # å®šä¹‰ RA/DEC å¯¹
    ra_dec_pairs = [
        ('RA', 'DEC'),
        ('RA_app', 'DEC_app'),
        # å¯ä»¥æ·»åŠ æ›´å¤šå¯¹
    ]
    
    formatted = {}
    processed_keys = set()
    
    # å¤„ç† RA/DEC å¯¹
    for ra_key, dec_key in ra_dec_pairs:
        if ra_key in data_dict and dec_key in data_dict:
            formatted[ra_key] = []
            formatted[dec_key] = []
            
            for ra_str, dec_str in zip(data_dict[ra_key], data_dict[dec_key]):
                try:
                    coord = SkyCoord(ra=ra_str, dec=dec_str, unit=(u.hourangle, u.deg))
                    formatted[ra_key].append(coord.ra.degree)
                    formatted[dec_key].append(coord.dec.degree)
                except:
                    formatted[ra_key].append(ra_str)
                    formatted[dec_key].append(dec_str)
            
            processed_keys.update([ra_key, dec_key])
    
    # å¤„ç†å…¶ä½™çš„é”®
    for key, values in data_dict.items():
        if key in processed_keys:
            continue
            
        if 'Date' in key or 'date' in key:
            # å¤„ç†æ—¥æœŸ
            formatted[key] = []
            for date_str in values:
                try:
                    if ':' in date_str:
                        fmt = "%Y-%b-%d %H:%M:%S" if date_str.count(':') == 2 else "%Y-%b-%d %H:%M"
                        dt = datetime.strptime(date_str, fmt)
                        formatted[key].append(Time(dt, scale='utc').isot)
                    else:
                        formatted[key].append(Time(float(date_str), format='jd', scale='utc').isot)
                except:
                    formatted[key].append(date_str)
        else:
            # å¤„ç†æ•°å€¼
            formatted[key] = []
            for value in values:
                if value in ['n.a.', 'n.a']:
                    formatted[key].append(np.nan)
                else:
                    try:
                        formatted[key].append(float(value))
                    except:
                        formatted[key].append(value)
    
    return formatted

def read_horizons_table(jpltabpath):
    """
    Expected JPL title list:
     Date__(UT)__HR:MN     R.A._____(ICRF)_____DEC   dRA*cosD d(DEC)/dt    T-mag   N-mag                
     r        rdot             delta      deldot     S-O-T /r     S-T-O    PsAng   PsAMV  
     Sky_motion  Sky_mot_PA  RelVel-ANG  Lun_Sky_Brt  sky_SNR
    """
    f = open(jpltabpath, 'r')
    jplfile = f.readlines()
    f.close()
    startline = jplfile.index('$$SOE\n') + 1
    endline = jplfile.index('$$EOE\n')
    titleline = startline - 3
    
    titles = jplfile[titleline]
    titles = titles.strip()
    title_list = titles.split(' ')
    title_list = [title for title in title_list if title != '']
    title_list_new = []
    for title in title_list:
        title = title.strip()
        if ('Date__(UT)__' in title) or (title == 'Date_________JDUT'): 
            title_list_new.append('date')
        elif title == 'R.A._____(ICRF)_____DEC': 
            title_list_new.append('RA')
            title_list_new.append('DEC')
        elif title == 'R.A.__(a-apparent)__DEC':
            title_list_new.append('RA_app')
            title_list_new.append('DEC_app')
        elif title == '/r': pass
        else: title_list_new.append(title)

    jpl_dict = {}
    for title in title_list_new:
        jpl_dict[title] = []

    jpltable = []
    for line in jplfile[startline:endline]:
        line_list = []
        line = line.strip()
        line_list = _parse_orbital_line(line)
        jpltable.append(line_list)

    for i, title in enumerate(title_list_new):
        for line_list in jpltable:
            jpl_dict[title].append(line_list[i])
    
    jpl_dict = _format_orbital_dict(jpl_dict)
    return jpl_dict

def get_eph_dict(eph):
    eph_table = Table(eph.table)
    eph_table = remove_table_units(eph_table)
    eph_dict = TableConverter.astropy_table_to_list_dict(eph_table)
    return eph_dict

def parse_date_string(date_str):
    """
    è§£æå„ç§æ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²
    
    æ”¯æŒæ ¼å¼:
    - '2025-10-10' (ISOæ ¼å¼)
    - '2025 Oct. 10' æˆ– '2025 Oct 10'
    - '2025 October 10'
    - '2025-Oct-10'
    """
    if not date_str:
        return None
    
    # æ¸…ç†å­—ç¬¦ä¸²
    date_str = date_str.strip()
    
    # å°è¯•ç›´æ¥ç”¨ Time è§£æï¼ˆISOæ ¼å¼ï¼‰
    try:
        return Time(date_str)
    except:
        pass

    # å¤„ç† YYYY-MM-DD.fraction ï¼ˆå°æ•°å¤©ï¼‰
    m = re.match(r'^(\d{4}-\d{2}-\d{2})\.(\d+)$', date_str)
    if m:
        base_date = m.group(1)
        frac_day = float("0." + m.group(2))
        return Time(base_date) + frac_day * u.day

    # å¤„ç† "2025 Oct. 10" è¿™ç§æ ¼å¼
    # ç§»é™¤ç‚¹å·
    #date_str = date_str.replace('.', '')
    date_str = re.sub(r'(?<=[A-Za-z])\.', '', date_str)
    
    # å°è¯•å„ç§æ ¼å¼
    formats_to_try = [
        "%Y %b %d",      # 2025 Oct 10
        "%Y %B %d",      # 2025 October 10
        "%Y-%b-%d",      # 2025-Oct-10
        "%Y/%b/%d",      # 2025/Oct/10
    ]
    
    for fmt in formats_to_try:
        try:
            dt = datetime.strptime(date_str, fmt)
            return Time(dt)
        except:
            continue
    
    # å¦‚æœéƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºé”™è¯¯
    raise ValueError(f"æ— æ³•è§£ææ—¥æœŸ: {date_str}")

def smart_float_format(x):
    abs_x = abs(x)
    # ç‰¹åˆ«å¤§æˆ–ç‰¹åˆ«å°ï¼šç”¨ç§‘å­¦è®¡æ•°æ³•
    if abs_x != 0 and (abs_x < 1e-3 or abs_x > 1e5):
        return f"{x:.3e}"
    # å¤§äº 1000 çš„æ™®é€šæ•°ï¼šä¿ç•™ä¸‰ä½å°æ•°
    elif abs_x >= 10:
        return f"{x:.3f}"
    # å…¶ä»–æƒ…å†µï¼šä¿ç•™ 4 ä½æœ‰æ•ˆæ•°å­—
    else:
        return f"{x:.4g}"  # g æ ¼å¼è‡ªåŠ¨åˆ‡æ¢ç§‘å­¦è®¡æ•°æ³•å’Œæµ®ç‚¹æ•°

def dates_to_plot_dates(date_input):
    """
    å°†å„ç§æ—¥æœŸè¾“å…¥è½¬æ¢ä¸º matplotlib plot_date æ•°å€¼
    
    å‚æ•°:
        date_input: å¯ä»¥æ˜¯:
            - str: å•ä¸ªæ—¥æœŸå­—ç¬¦ä¸²
            - Time: å•ä¸ª astropy Time å¯¹è±¡
            - list/array: åŒ…å« str æˆ– Time å¯¹è±¡çš„åˆ—è¡¨
            - æ··åˆåˆ—è¡¨: åŒæ—¶åŒ…å« str å’Œ Time å¯¹è±¡
    
    è¿”å›:
        - å•ä¸ªè¾“å…¥: float (plot_date æ•°å€¼)
        - åˆ—è¡¨è¾“å…¥: numpy array (plot_date æ•°å€¼æ•°ç»„)
    """
    
    def convert_single_date(date):
        """è½¬æ¢å•ä¸ªæ—¥æœŸä¸º plot_date"""
        if isinstance(date, Time):
            # å·²ç»æ˜¯ Time å¯¹è±¡
            dt = date.to_datetime()
        elif isinstance(date, str):
            # å­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æ
            try:
                # å°è¯•ç›´æ¥ç”¨ Time è§£æ
                t = Time(date)
            except:
                # ä½¿ç”¨ parse_date_string å¤„ç†å…¶ä»–æ ¼å¼
                t = parse_date_string(date)
            dt = t.to_datetime()
        elif isinstance(date, datetime):
            # å·²ç»æ˜¯ datetime å¯¹è±¡
            dt = date
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ—¥æœŸç±»å‹: {type(date)}")
        
        return float(mdates.date2num(dt))
    
    # æ£€æŸ¥è¾“å…¥ç±»å‹
    if isinstance(date_input, (str, Time, datetime)):
        # å•ä¸ªè¾“å…¥
        return convert_single_date(date_input)
    
    elif hasattr(date_input, '__iter__'):
        # å¯è¿­ä»£å¯¹è±¡ï¼ˆåˆ—è¡¨ã€æ•°ç»„ç­‰ï¼‰
        plot_dates = []
        for date in date_input:
            plot_dates.append(convert_single_date(date))
        return plot_dates
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥ç±»å‹: {type(date_input)}")

